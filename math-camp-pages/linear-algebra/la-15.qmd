---
title: "Chapter 15: Eigenvectors and eigenvalues"
format: html
---

#

Very basic question here. *What* has eigenvectors/eigenvalues?
A: Matrices (transformations)

Just glancing at the transformation matrix $$\textbf A = \begin{bmatrix} 3 & 0 \\ 4 & 8 \end{bmatrix}$$, which vectors are going to stay on the line they span after the transformation $\textbf A \boldsymbol v$?

Answer: Vectors of the form $\begin{bmatrix} 0 & j\end{bmatrix}$

What is an eigenvector's eigenvalue?
An eigenvalue is the factor by which the eigenvector is stretched or squished. It's the eigenvector's associated scalar.^[In fact, I really think eigenvalue should have been "eigenscalar," but that's what they get for asking this *Eigen* guy to name it.]

How can you interpret the eigenvector of a 3D transformation?
A: This is a bit of a trick question. If its eigenvalue is 1, then that eigenvector is the axis of rotation of the transformation. Remember that rotations in the 2D plane didn't have (real) eigenvalues!

What is *the* equation that unites eigenvectors with eigenvalues?
$\textbf A \vec{v} = \lambda \vec{v}$

How do you transform $\textbf A \vec{v} = \lambda \vec{v}$ so that the left-hand side is matrix-vector multiplication (the right side already is!)?
You insert an identity matrix! $\textbf A \vec{v} = \lambda \boldsymbol I_n\vec{v}$

What equation do you set up to solve for $\vec{v} \text{ and } \lambda$? Hint: start with the result of the previous problem.

$\textbf A \vec{v} = \lambda \boldsymbol I_n\vec{v} \\ \textbf A \vec{v} - \lambda \boldsymbol I_n\vec{v} = \vec 0 \\ (\textbf A  - \lambda \boldsymbol I_n)\vec{v} =\vec 0$

Then, since $\vec{v} \neq \vec 0$, we know that $\text{det}(\textbf A  - \lambda \boldsymbol I_n) = 0$. 

XXX
Geometrically, why do we want $\text{det}(\textbf A  - \lambda \boldsymbol I_n) = 0$?
???

What's a shear?
https://en.wikipedia.org/wiki/Shear_mapping

[There's definitely stuff missing here]

What's the "eigen interpretation" of a diagonal matrix?
Its columns are where the basis vectors end up. Importantly, they end up on the line that they originally spanned. This means that the diagonal entries (scalars) are the eigenvalues (the amount by which the basis vector is scaled).

Show/prove to your own satisfaction why it is the case that the eigenvectors of a diagonal matrix are basis vectors and their eigenvalues are the diagonal entries of the matrix.

What's an eigenbasis?

When can you (not) get an eigenbasis?

How do you get a matrix into its eigenbasis?

How does an eigenbasis help you exponentiate a matrix?

TODO: Insert Markov example

There's the problem to do at the end.

You should probably bring up positive definite here! And also ... Linear Models in Matrix Form. Check out that book's section on positive definite.

What's the "eigen-interpretation" of a diagonal matrix?
Its columns are where the basis vectors end up. Importantly, they end up on their original span, meaning that they're eigenvectors! This makes the diagonal values their corresponding eigenvalues

What's an eigenbasis?
It's unclear, but I think it's just a basis for the space we're talking about where each column is ... now I'm lost.

When can you (not) get an eigenbasis?
You need enough eigenvectors to span the full space

(Not sure that this question is even phrased right)
How do you get a matrix into its eigenbasis?

Eigenvalues are roots of a matrix's characteristic polynomial

How does GS represent the idea that tr(A) = \sum \lambda_i?
$n^{-1} = n^{-1} \sum \lambda_i$ (the mean)

$det A = ad - bc = \lambda_1 \lambda_2$

The shortcut is $m \pm \sqrt{m^2-p}$

I have no idea where this question came from: Confirm that the product of the eigenvalues of $\begin{bmatrix} c&a-bi \\ a+bi&c \end{bmatrix}$ is -1 if $a^2 + b^2 + c^2 = 1$

At 12.20 we the homework. The mission is to prove how the determinant and trace are related to eigenvalues. Specifically, prove that $det A = \lambda_1 \lambda_2$ and the trace fact.
He gives us the quadratic \lambda^2 - (a+d)\lambda + (ad-bc) and says taht there's something about these coefficients $-(a+d)$ and and $ad-bc$.

Extras:
What would the eigenvalues of a singular matrix be? Why?

Justin, can you give an inkling into how eigenvalues are used in dimensionality reduction?